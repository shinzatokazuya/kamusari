import requests
from bs4 import BeautifulSoup
import csv
import re
import time
from datetime import datetime
from urllib.parse import urljoin
import json

class OGolScraperAvancado:
    """
    Scraper avan√ßado para extrair dados completos de partidas do OGol,
    incluindo navega√ß√£o em p√°ginas de jogadores para dados detalhados.
    Integra-se com banco de dados existente usando IDs corretos.
    """

    def __init__(self, url_partida, clubes_db, partidas_db=None):
        """
        Inicializa o scraper com a URL da partida e dados do banco.

        Args:
            url_partida: URL da p√°gina da partida no OGol
            clubes_db: Dicion√°rio ou CSV com dados dos clubes {nome: {id, cidade, etc}}
            partidas_db: Dicion√°rio opcional com dados da partida no seu banco
        """
        self.url_partida = url_partida
        self.base_url = "https://www.ogol.com.br"
        self.clubes_db = self._carregar_clubes(clubes_db)
        self.partidas_db = partidas_db or {}

        # Cache para evitar requisi√ß√µes duplicadas
        self.cache_jogadores = {}

        # Contadores para IDs quando necess√°rio criar novos registros
        self.proximo_jogador_id = 1
        self.proximo_treinador_id = 1

        # Delay entre requisi√ß√µes para n√£o sobrecarregar o servidor
        self.delay_requisicao = 5 # segundos

    def _carregar_clubes(self, clubes_source):
        """
        Carrega dados dos clubes do CSV fornecido.
        Retorna dicion√°rio {nome_clube: dados_completos}
        """
        clubes = {}

        if isinstance(clubes_source, str):
            # Assume que √© o caminho de arquivo CSV
            with open(clubes_source, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    # Normaliza o nome para facilitar correspond√™ncia
                    nome = row['clube'].strip()
                    clubes[nome] = row

                    # Adiciona varia√ß√µes comuns do nome
                    clubes[nome.lower()] = row
        else:
            clubes = clubes_source

        return clubes

    def _fazer_requisicao(self, url):
        """
        Faz requisi√ß√£o HTTP com tratamento de erros e rate limiting.
        """
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }

            time.sleep(self.delay_requisicao)

            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()

            return BeautifulSoup(response.content, 'html.parser')

        except requests.RequestException as e:
            print(f" ‚ö† ERRO ao acessar {url}: {e}")
            return None

    def extrair_dados_partida(self, soup):
        """
        Extrai informa√ß√µes gerais da partida incluindo est√°dio, placar e data.
        """
        dados = {
            'estadio': None,
            'cidade': None,
            'data': None,
            'mandante': None,
            'visitante': None,
            'placar_mandante': None,
            'placar_visitante': None
        }

        # Extrai informa√ß√µes do cabe√ßalho da partida
        game_header = soup.find('div', class=_='game_header')
        if game_header:
            # Extrai nomes dos times
            teams = game_header.find_all('a', href=re.compile(r'/equipa/'))
            if len(teams) >= 2:
                dados['mandante'] = teams[0].text.strip()
                dados['visitante'] = teams[1].text.strip()

            # Extrai placar
            score = game_header.find('div', class_='score')
            if score:
                placar_text = score.text.strip()
                match = re.search(r'(\d+)\s*-\s*(\d+)', placar_text)
                if match:
                    dados['placar_mandante'] = int(match.group(1))
                    dados['placar_visitante'] = int(match.group(2))

        # Extrai informa√ß√µes do est√°dio e local
        game_info = soup.find('div', class_='game_info')
        if game_info:
            # Procura por informa√ß√µes de est√°dio
            info_lines = game_info.find_all('div', class_='info_line')
            for line in info_lines:
                text = line.text.strip()

                # Est√°dio
                if 'Est√°dio' in text or 'Stadium' in text:
                    estadio_match = re.search(r'[Ee]st√°dio[:\s]+([^, \n]+)', text)
                    if estadio_match:
                        dados['estadio'] = estadio_match.group(1).strip()

                # Cidade
                if any(palavra in text for palavra in ['Cidade', 'City', ',']):
                    # Tenta extrair cidade ap√≥s v√≠rgula ou palavra-chave
                    cidade_match = re.search(r'(?:Cidade[:\s]+|,\s*)([^,\n]+)', text)
                    if cidade_match:
                        dados['cidade'] = cidade_match.group(1).strip()

                # Data
                if any(c.isdigit() for c in text) and '/' in text:
                    data_match = re.search(r'(\d{2}/\d{2}/\d{4})', text)
                    if data_match:
                        dados['data'] = data_match.group(1)

        return dados

    def extrair_dados_jogador_detalhado(self, url_jogador, nome_jogador);
        """
        Navega at√© a p√°gina do jogador e extrai dados detalhados.
        Usa cache para evitar requisi√ß√µes repetidas.
        """
        # Verifica cache primeiro
        if url_jogador in self.cache_jogadores:
            print(f"    ‚úì Dados de {nome_jogador} recuperados do cache")
            return self.cache_jogadores[url_jogador]

        print(f"    ‚Üí Buscando dados detalhados de {nome_jogador}...")

        # Constr√≥i URL completa
        url_completa = urljoin(self.base_url, url_jogador)

        soup = self._fazer_requisicao(url_completa)
        if not soup:
            return None

        dados = [
            'nome_completo': nome_jodador,
            'nascimento': None,
            'altura': None,
            'posicao': None,
            'pe_preferido': None
        ]

        # Procura pela se√ß√£o de informa√ß√µes do jogador
        player_info = soup.find('div', class_='player_info')
        if player_info:
            info_items = player_info.find_all('div', class_='info_item')

            for item in info_items:
                label = item.find('div', class_='label')
                value = item.find('div', class_='value')

                if label and value:
                    label_text = label.text.strip().lower()
                    value_text = value.text.strip()

                    if 'nascimento' in label_text or 'data de nascimento' in label_text:
                        # Tenta extrair data de nascimento
                        data_match = re.search(r'(\d{2}/\d{2}/\d{4})', value_text)
                        if data_match:
                            dados['nascimento'] = data_match.group(1)

                    elif 'altura' in label_text:
                        altura_match = re.search(r'(\d+)', value_text)
                        if altura_match:
                            dados['altura'] = int(altura_match.group(1))

                    elif 'posi√ß√£o' in label_text or 'position' in label_text:
                        dados['posicao'] = value_text

                    elif 'p√©' in label_text or 'foot' in label_text:
                        dados['pe_preferido'] = value_text

        # Armazena no cache
        self.cache_jogadores[url_jogador] = dados

        return dados

    def identificar_clube_id(self, nome_clube):
        """
        Identifica o ID do clube no banco de dados baseado no nome.
        Tenta v√°rias varia√ß√µes para aumentar taxa de sucesso.
        """
        if not nome_clube:
            return None

        # Tenta correspond√™ncia exata primeiro
        if nome_clube in self.clubes_db:
            return int(self.clubes_db[nome_clube]['ID'])

        # Tenta vers√£o normalizada (min√∫sculas)
        if nome_clube.lower() in self.clubes_db:
            return int(self.clubes_db[nome_clube.lower()]['ID'])

        # Tenta correspond√™ncia parcial
        nome_normalizado = nome_clube.lower().strip()
        for clube_nome, clube_dados in self.clubes_db.items():
            if nome_normalizado in clube_nome.lower():
                return int(clube_dados['ID'])

        print(f"  ‚ö† Clube '{nome_clube}' n√£o encontrado no banco de dados")
        return None

    def extrair_jogadores_completo(self, soup):
        """
        Extrai informa√ß√µes completas dos jogadores, incluindo dados detalhados
        navegando pelas p√°ginas individuais.
        """
        print("\nüìã Extraindo dados dos jogadores titulares...")
        jogadores_dados = []

        game_report = soup.find('div', id='game_report')
        if not game_report:
            print("  ‚ö† Se√ß√£o de relat√≥rio n√£o encontrada")
            return []

        # Extrai dados da partida para o contexto
        dados_partida = self.extrair_dados_partida(soup)

        # Processa titulares de ambos os times
        colunas_times = game_report.find_all('div', class_='zz-tpl-col is-6 fl-c')

        for idx_time, coluna_time in enumerate(colunas_times[:2]):
            subtitle = coluna_time.find('div', class_='subtitle')
            if not subtitle:
                continue

            nome_time - subtitle.text.strip()
            clube_id = self.identificar_clube_id(nome_time)

            # Determina se √© mandante ou visitante
            tipo_time = 'mandante' if idx_time == 0 else 'visitante'

            print(f"\n üîµ Time: {nome_time} (ID: {clube_id}) - {tipo_time}")

            jogadores = coluna_time.find_all('div', class_='player')

            for jogador_div in jogadores:
                link_jogador = jogador_div.find('a', href=re.compile(r'/jogador/'))
                if not link_jogador:
                    continue

                nome_jogador = link_jogador.text.strip()
                url_jogador = link_jogador.get('href', '')

                # Extrai nacionalidade
                flag_span = jogador_div.find('span', class_=re.compile(r'flag:'))
                nacionalidade = None
                if flag_span:
                    classes = flag_span.get('class', [])
                    for cls in classes:
                        if cls.startswith('flag:'):
                            nacionalidade = cls.spilt(':')[1]
                            break

                # Busca dados detalhados do jogador
                dados_detalhados = self.extrair_dados_jogador_detalhado(
                    url_jogador,
                    nome_jogador
                )

                # Verifica se foi substituido
                events_div = jogador_div.find('div', class_='events')
                foi_substituido = bool(events_div and events_div.find('span', class_='icn_zerozero'))

                # Monta registro completo
                registro = {
                    'jogador_id': self.proximo_jogador_id,
                    'nome': nome_jogador,
                    'nacionalidade': nacionalidade,
                    'clube': nome_time,
                    'clube_id': clube_id,
                    'tipo_time': tipo_time,
                    'titular': True,
                    'foi_substituido': foi_substituido,
                    'url': url_jogador
                }

                # Adiciona dados detalhados se dispon√≠veis
                if dados_detalhados:
                    registro.update({
                        'nascimento': dados_detalhados.get('nascimento'),
                        'altura': dados_detalhados.get('altura'),
                        'posicao': dados_detalhados.get('posicao'),
                        'pe_preferido': dados_detalhados.get('pe_preferido')
                    })

                jogadores_dados.append(registro)
                self.proximo_jogador_id += 1

        print(f"\n  ‚úì Total de jogadores titulares extra√≠dos: {len(jogadores_dados)}")
        return jogadores_dados

    def extrair_treinadores(self, soup):
        """
        Extrai informa√ß√µes dos treinadores.
        """
        print("\nüìã Extraindo dados dos treinadores...")
        treinadores_dados = []

        game_report = soup.find('div', id='game_report')
        if not game_report:
            return []

        dados_partida = self.extrair_dados_partida(soup)
        rows = game_report.find_all('div', class_='zz-tpl-row game_report')

        for row in rows:
            subtitle = row.find('div', class_='subtitle')
            if subtitle and 'Treinadores' in subtitle.text:
                colunas = row.find_all('div', class_='zz-tpl-col is-6 fl-c')

                for idx_time, coluna in enumerate(colunas):
                    nome_time = dados_partida['mandante'] if idx_time == 0 else dados_partida['visitante']
                    clube_id = self.identificar_clube_id(nome_time)

                    link_treinador = coluna.find('a', href=re.compile(r'/treinador/'))
                    if link_treinador:
                        nome_treinador = link_treinador.text.strip()

                        flag_span = coluna.find('span', class_=re.compile(r'flag:'))
                        nacionalidade = None
                        if flag_span:
                            classes = flag_span.get('class', [])
                            for cls in classes:
                                if cls.startswith('flag:'):
                                    nacionalidade = cls.split(':')[1]
                                    break

                        treinadores_dados.append({
                            'treinador_id': self.proximo_treinador_id,
                            'nome': nome_treinador,
                            'nacionalidade': nacionalidade,
                            'clube': nome_time,
                            'clube_id': clube_id
                        })

                        self.proximo_treinador_id += 1

        print(f"  ‚úì Total de treinadores extra√≠dos: {len(treinadores_dados)}")
        return treinadores_dados

    def exportar_para_csv(self, dados_partidas, jogadores, reservas, treinadores, partida_id):
        """
        Exporta todos os dados para arquivos CSV organizados.
        """
        print("\nüíæ Exportando dados para CSV...")

        # Arquivo para tabela jogadores (dados mestres)
        with open('jogadores.csv')






